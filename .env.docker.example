DOCINT_OFFLINE=true
ENABLE_IE=true
LLM=model-q4_k_m.gguf
VLM=model-vision-q4_k_m.gguf
IE_MAX_WORKERS=4
# Llama.cpp Configuration (Uncomment to override defaults)
# LLAMA_CPP_N_GPU_LAYERS=-1  # -1 = offload all layers to GPU, 0 = CPU only
# LLAMA_CPP_CTX_WINDOW=8192
# LLAMA_CPP_TEMPERATURE=0.0